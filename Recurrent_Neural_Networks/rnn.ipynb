{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fae45f0",
   "metadata": {},
   "source": [
    "## IMPLEMENT A RNNS LANGUAGE MODEL FOR PREDICTING WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca72d61",
   "metadata": {},
   "source": [
    "### STEP 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb668aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.build_vocab import Vocab\n",
    "from utils.Trainer import RNNTrainer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4580c",
   "metadata": {},
   "source": [
    "### STEP 2: Download and preprocessing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef28ae4",
   "metadata": {},
   "source": [
    "2.1. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d130d6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\VSCode\\DL_self_practice\\Recurrent_Neural_Networks\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282e1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from a given url\n",
    "url = \"https://www.gutenberg.org/cache/epub/84/pg84.txt\"\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "response = requests.get(url)\n",
    "filename = \"../data/gutenberg_book.txt\"\n",
    "\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916125dc",
   "metadata": {},
   "source": [
    "2.2. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88070b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data, the trained tokens will be separate words\n",
    "import re\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = re.sub('[^A-Za-z]+', ' ', text).lower()\n",
    "words = text.split()\n",
    "\n",
    "vocab = Vocab(words)\n",
    "encoded = vocab[words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f877e7",
   "metadata": {},
   "source": [
    "### STEP 3: Build a specialize Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f87c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset(Dataset):\n",
    "    def __init__(self, data, num_steps):\n",
    "        self.data = data\n",
    "        self.num_steps = num_steps\n",
    "\n",
    "    # Number of samples\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.num_steps\n",
    "    \n",
    "    # Method to get samples based on index\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index: index + self.num_steps]\n",
    "        y = self.data[index + 1: index + self.num_steps + 1]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8470ca3",
   "metadata": {},
   "source": [
    "Create dataloader which supports training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f46467",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "train_data, test_data = train_test_split(encoded, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = WordDataset(train_data, num_steps)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = WordDataset(test_data, num_steps)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc0c7a",
   "metadata": {},
   "source": [
    "### STEP 4: Build a language model based on RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2366c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dims, num_hiddens, num_layers=1):\n",
    "        super(LMRNN, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dims)\n",
    "        self.rnn = nn.RNN(embedding_dims, num_hiddens, num_layers)\n",
    "        self.fc = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, state=None):\n",
    "        # input -> shape: (num_steps, batch_size)\n",
    "        # x -> shape: (num_steps, batch_size, embedding_dims)\n",
    "        x = self.embed(inputs)\n",
    "        # out -> shape: (num_steps, batch_size, num_hiddens)\n",
    "        # hn -> shape: (num_layers, batch_size, num_hiddens)\n",
    "        out, hn = self.rnn(x, state)\n",
    "        # y -> shape: (num_steps, batch_size, vocab_size)\n",
    "        y = self.fc(out)\n",
    "        return y, hn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11fa95",
   "metadata": {},
   "source": [
    "### STEP 5: Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97afeea",
   "metadata": {},
   "source": [
    "5.1. Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d6df1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dims = 128\n",
    "num_hiddens = 256\n",
    "num_layers = 5\n",
    "epochs = 10\n",
    "gradient_clip_val = 1.0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LMRNN(vocab_size, embedding_dims, num_hiddens, num_layers).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.25)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa497fce",
   "metadata": {},
   "source": [
    "5.2. Create a trainer for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a58c8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RNNTrainer(model, train_loader, test_loader, vocab_size, lr, num_epochs, gradient_clip_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d301ebd",
   "metadata": {},
   "source": [
    "5.3. Start traing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e841df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = trainer.train_loss, trainer.test_loss\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c1bac",
   "metadata": {},
   "source": [
    "5.4. Showing train loss and test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot()\n",
    "print(f'Training loss at the last epoch: {train_loss[-1]}')\n",
    "print(f'Testing loss at the last epoch: {test_loss[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce0164",
   "metadata": {},
   "source": [
    "### STEP 6: Build functions for predicting words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ae9d4",
   "metadata": {},
   "source": [
    "6.1. Build a function for predicting the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, start_text):\n",
    "    model.eval()\n",
    "    words = start_text.lower().split()\n",
    "    inputs = torch.tensor(vocab[words], dtype=torch.long).to(device)\n",
    "    # Converts inputs to (num_steps, batch_size=1)\n",
    "    inputs = inputs.reshape(-1, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y, _ = model(inputs)\n",
    "        last_word_digits = y[-1, 0, :]\n",
    "        predicted_idx = torch.argmax(last_word_digits).item()\n",
    "        predicted_word = vocab.to_tokens(predicted_idx)\n",
    "    return predicted_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f2bd5",
   "metadata": {},
   "source": [
    "6.2. Build a function for predicting a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03603db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_sequence(model, start_text, seq_len):\n",
    "    model.eval()\n",
    "    words = start_text.lower().split()\n",
    "    inputs = torch.tensor(vocab[words], dtype=torch.long).to(device)\n",
    "    inputs = inputs.reshape(-1, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(seq_len):\n",
    "            out, _ = model(inputs)\n",
    "            next_word_idx = torch.argmax(out[-1, 0, :]).item()\n",
    "            next_word = vocab.to_tokens(next_word_idx)\n",
    "            words.append(next_word)\n",
    "            # Take 'seq_len' words in 'words' to feed into the model\n",
    "            inputs = torch.tensor([vocab[w] for w in words[-num_steps:]]).T.to(device)\n",
    "    \n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c377f86",
   "metadata": {},
   "source": [
    "6.3. Implementing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce11a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I was traveling around the city\"\n",
    "print(predict_next_word(model, prompt))\n",
    "print(predict_next_sequence(model, prompt, 20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
